{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4b1716",
   "metadata": {},
   "source": [
    "# cats and dogs classification using unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f465c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c72612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir=os.path.join('datasets/PetImages')\n",
    "os.listdir(base_dir)\n",
    "train_dir=os.path.join(base_dir,'train')\n",
    "train_cat_dir=os.path.join(base_dir,'Cat')\n",
    "train_dog_dir=os.path.join(base_dir,'Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196f5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1b7b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9470464   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,494,561\n",
      "Trainable params: 9,494,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d56153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411455b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24959 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1.0/255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "# validation_generator=test_datagen.flow_from_directory(\n",
    "#     validation_dir,\n",
    "#     batch_size=20,\n",
    "#     class_mode='binary',\n",
    "#     target_size=(150,150)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 8,
>>>>>>> origin/main
   "id": "b1d879e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/10\n",
      "  41/1248 [..............................] - ETA: 1:24 - loss: 1.3963 - accuracy: 0.5207"
=======
      "Epoch 1/50\n",
      " 796/1248 [==================>...........] - ETA: 17s - loss: 0.6073 - accuracy: 0.6868"
>>>>>>> origin/main
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
=======
      "E:\\anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
>>>>>>> origin/main
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "1248/1248 [==============================] - 85s 64ms/step - loss: 0.5995 - accuracy: 0.6918\n",
      "Epoch 2/10\n",
      "1248/1248 [==============================] - 80s 64ms/step - loss: 0.4573 - accuracy: 0.7874\n",
      "Epoch 3/10\n",
      "1248/1248 [==============================] - 72s 58ms/step - loss: 0.4027 - accuracy: 0.8200\n",
      "Epoch 4/10\n",
      "1248/1248 [==============================] - 105s 84ms/step - loss: 0.3696 - accuracy: 0.8417\n",
      "Epoch 5/10\n",
      "1248/1248 [==============================] - 112s 89ms/step - loss: 0.3408 - accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "1248/1248 [==============================] - 68s 55ms/step - loss: 0.3253 - accuracy: 0.8666\n",
      "Epoch 7/10\n",
      "1248/1248 [==============================] - 76s 61ms/step - loss: 0.3137 - accuracy: 0.8752\n",
      "Epoch 8/10\n",
      "1248/1248 [==============================] - 78s 62ms/step - loss: 0.3052 - accuracy: 0.8793\n",
      "Epoch 9/10\n",
      "1248/1248 [==============================] - 77s 62ms/step - loss: 0.3046 - accuracy: 0.8830\n",
      "Epoch 10/10\n",
      "1248/1248 [==============================] - 77s 62ms/step - loss: 0.2992 - accuracy: 0.8868\n"
=======
      "1248/1248 [==============================] - 54s 39ms/step - loss: 0.5664 - accuracy: 0.7139\n",
      "Epoch 2/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.4376 - accuracy: 0.7998\n",
      "Epoch 3/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.3818 - accuracy: 0.8338\n",
      "Epoch 4/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.3396 - accuracy: 0.8561\n",
      "Epoch 5/50\n",
      "1248/1248 [==============================] - 46s 37ms/step - loss: 0.3129 - accuracy: 0.8723\n",
      "Epoch 6/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.2881 - accuracy: 0.8876\n",
      "Epoch 7/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2751 - accuracy: 0.8931\n",
      "Epoch 8/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2709 - accuracy: 0.8997\n",
      "Epoch 9/50\n",
      "1248/1248 [==============================] - 48s 39ms/step - loss: 0.2562 - accuracy: 0.9068\n",
      "Epoch 10/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.2559 - accuracy: 0.9090\n",
      "Epoch 11/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2559 - accuracy: 0.9082\n",
      "Epoch 12/50\n",
      "1248/1248 [==============================] - 48s 39ms/step - loss: 0.2558 - accuracy: 0.9074\n",
      "Epoch 13/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.2650 - accuracy: 0.9066\n",
      "Epoch 14/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2799 - accuracy: 0.9020\n",
      "Epoch 15/50\n",
      "1248/1248 [==============================] - 48s 39ms/step - loss: 0.2812 - accuracy: 0.9045\n",
      "Epoch 16/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.2717 - accuracy: 0.9061\n",
      "Epoch 17/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2896 - accuracy: 0.9010\n",
      "Epoch 18/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.2863 - accuracy: 0.9022\n",
      "Epoch 19/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2795 - accuracy: 0.9008\n",
      "Epoch 20/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2905 - accuracy: 0.8964\n",
      "Epoch 21/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.3163 - accuracy: 0.8966\n",
      "Epoch 22/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.3071 - accuracy: 0.8958\n",
      "Epoch 23/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.3083 - accuracy: 0.8996\n",
      "Epoch 24/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.2989 - accuracy: 0.8980\n",
      "Epoch 25/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.3014 - accuracy: 0.8979\n",
      "Epoch 26/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2973 - accuracy: 0.8964\n",
      "Epoch 27/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.2925 - accuracy: 0.9008\n",
      "Epoch 28/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.2903 - accuracy: 0.9042\n",
      "Epoch 29/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.2799 - accuracy: 0.9028\n",
      "Epoch 30/50\n",
      "1248/1248 [==============================] - 48s 39ms/step - loss: 0.2860 - accuracy: 0.9018\n",
      "Epoch 31/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2827 - accuracy: 0.9009\n",
      "Epoch 32/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.2790 - accuracy: 0.9055\n",
      "Epoch 33/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.2835 - accuracy: 0.9103\n",
      "Epoch 34/50\n",
      "1248/1248 [==============================] - 47s 37ms/step - loss: 0.2663 - accuracy: 0.9099\n",
      "Epoch 35/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2770 - accuracy: 0.9051\n",
      "Epoch 36/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.2777 - accuracy: 0.9068\n",
      "Epoch 37/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2669 - accuracy: 0.9058\n",
      "Epoch 38/50\n",
      "1248/1248 [==============================] - 46s 37ms/step - loss: 0.2956 - accuracy: 0.9049\n",
      "Epoch 39/50\n",
      "1248/1248 [==============================] - 77s 61ms/step - loss: 0.2883 - accuracy: 0.9037\n",
      "Epoch 40/50\n",
      "1248/1248 [==============================] - 96s 77ms/step - loss: 0.2946 - accuracy: 0.9085\n",
      "Epoch 41/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.2843 - accuracy: 0.9059\n",
      "Epoch 42/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.3051 - accuracy: 0.9055\n",
      "Epoch 43/50\n",
      "1248/1248 [==============================] - 48s 38ms/step - loss: 0.2797 - accuracy: 0.9069\n",
      "Epoch 44/50\n",
      "1248/1248 [==============================] - 49s 39ms/step - loss: 0.2815 - accuracy: 0.9065\n",
      "Epoch 45/50\n",
      "1248/1248 [==============================] - 53s 42ms/step - loss: 0.3272 - accuracy: 0.9003\n",
      "Epoch 46/50\n",
      "1248/1248 [==============================] - 51s 41ms/step - loss: 0.4095 - accuracy: 0.9014\n",
      "Epoch 47/50\n",
      "1248/1248 [==============================] - 48s 38ms/step - loss: 0.2906 - accuracy: 0.9033\n",
      "Epoch 48/50\n",
      "1248/1248 [==============================] - 47s 38ms/step - loss: 0.3132 - accuracy: 0.9043\n",
      "Epoch 49/50\n",
      "1248/1248 [==============================] - 46s 37ms/step - loss: 0.3027 - accuracy: 0.9004\n",
      "Epoch 50/50\n",
      "1248/1248 [==============================] - 46s 37ms/step - loss: 0.3062 - accuracy: 0.9009\n"
>>>>>>> origin/main
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "  train_generator,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07922aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n",
      "[0.06510016]\n",
      "cat1.jpgis a cat\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[0.7054028]\n",
      "cat2.jpgis a dog\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[4.0185987e-05]\n",
      "cat3.jpgis a cat\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[2.176378e-08]\n",
      "cat4.jpegis a cat\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[0.9999796]\n",
      "dog1.jpgis a dog\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[0.99999845]\n",
      "dog2.jpegis a dog\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[0.74952465]\n",
      "dog3.jpgis a dog\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "[0.9995029]\n",
      "dog4.jpegis a dog\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[0.70235324]\n",
      "dog5.jpgis a dog\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[0.9926063]\n",
      "dog6.jpgis a dog\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[0.9999995]\n",
      "dog7.jpgis a dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "image_directory='datasets/PetImages/prediction/cats&dogs/'\n",
    "image_files=os.listdir(image_directory)\n",
    "images=[]\n",
    "for image_file in image_files:\n",
    "    image_path=os.path.join(image_directory,image_file)\n",
    "    image=load_img(image_path,target_size=(150,150))\n",
    "    image_array=img_to_array(image)\n",
    "    image_array/=255.0\n",
    "    x=np.expand_dims(image_array,axis=0)\n",
    "    images=np.vstack([x])\n",
    "    classes=model.predict(images,batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(image_file + 'is a dog')\n",
    "    else:\n",
    "        print(image_file + 'is a cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e0bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats&dogs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556785d-311b-4486-a409-dff9be261741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
