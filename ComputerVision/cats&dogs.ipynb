{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4b1716",
   "metadata": {},
   "source": [
    "# cats and dogs classification using unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f465c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c72612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir=os.path.join('datasets/PetImages')\n",
    "os.listdir(base_dir)\n",
    "train_dir=os.path.join(base_dir,'train')\n",
    "train_cat_dir=os.path.join(base_dir,'Cat')\n",
    "train_dog_dir=os.path.join(base_dir,'Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196f5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1b7b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9470464   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,494,561\n",
      "Trainable params: 9,494,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d56153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411455b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24959 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1.0/255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "# validation_generator=test_datagen.flow_from_directory(\n",
    "#     validation_dir,\n",
    "#     batch_size=20,\n",
    "#     class_mode='binary',\n",
    "#     target_size=(150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d879e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  41/1248 [..............................] - ETA: 1:24 - loss: 1.3963 - accuracy: 0.5207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 85s 64ms/step - loss: 0.5995 - accuracy: 0.6918\n",
      "Epoch 2/10\n",
      "1248/1248 [==============================] - 80s 64ms/step - loss: 0.4573 - accuracy: 0.7874\n",
      "Epoch 3/10\n",
      "1248/1248 [==============================] - 72s 58ms/step - loss: 0.4027 - accuracy: 0.8200\n",
      "Epoch 4/10\n",
      "1248/1248 [==============================] - 105s 84ms/step - loss: 0.3696 - accuracy: 0.8417\n",
      "Epoch 5/10\n",
      "1248/1248 [==============================] - 112s 89ms/step - loss: 0.3408 - accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "1248/1248 [==============================] - 68s 55ms/step - loss: 0.3253 - accuracy: 0.8666\n",
      "Epoch 7/10\n",
      "1248/1248 [==============================] - 76s 61ms/step - loss: 0.3137 - accuracy: 0.8752\n",
      "Epoch 8/10\n",
      "1248/1248 [==============================] - 78s 62ms/step - loss: 0.3052 - accuracy: 0.8793\n",
      "Epoch 9/10\n",
      "1248/1248 [==============================] - 77s 62ms/step - loss: 0.3046 - accuracy: 0.8830\n",
      "Epoch 10/10\n",
      "1248/1248 [==============================] - 77s 62ms/step - loss: 0.2992 - accuracy: 0.8868\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "  train_generator,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07922aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 144ms/step\n",
      "[0.02054421]\n",
      "cat1.jpgis a cat\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "[0.111196]\n",
      "cat2.jpgis a cat\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "[1.3424751e-06]\n",
      "cat3.jpgis a cat\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[3.94018e-13]\n",
      "cat4.jpegis a cat\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[0.9925296]\n",
      "dog1.jpgis a dog\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "[0.9606985]\n",
      "dog2.jpegis a dog\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[0.26235214]\n",
      "dog3.jpgis a cat\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "[0.9983346]\n",
      "dog4.jpegis a dog\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "[0.00176856]\n",
      "dog5.jpgis a cat\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[0.04155992]\n",
      "dog6.jpgis a cat\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "[0.00648604]\n",
      "dog7.jpgis a cat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "model=tf.keras.models.load_model('datasets/cats&dogs.h5')\n",
    "image_directory='datasets/PetImages/prediction/cats&dogs/'\n",
    "image_files=os.listdir(image_directory)\n",
    "images=[]\n",
    "for image_file in image_files:\n",
    "    image_path=os.path.join(image_directory,image_file)\n",
    "    image=load_img(image_path,target_size=(150,150))\n",
    "    image_array=img_to_array(image)\n",
    "    image_array/=255.0\n",
    "    x=np.expand_dims(image_array,axis=0)\n",
    "    images=np.vstack([x])\n",
    "    classes=model.predict(images,batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(image_file + 'is a dog')\n",
    "    else:\n",
    "        print(image_file + 'is a cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
