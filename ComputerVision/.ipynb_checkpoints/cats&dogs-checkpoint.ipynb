{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4b1716",
   "metadata": {},
   "source": [
    "# cats and dogs classification using unet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f465c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c72612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir=os.path.join('datasets/PetImages')\n",
    "os.listdir(base_dir)\n",
    "train_dir=os.path.join(base_dir,'train')\n",
    "train_cat_dir=os.path.join(base_dir,'Cat')\n",
    "train_dog_dir=os.path.join(base_dir,'Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196f5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1b7b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9470464   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,494,561\n",
      "Trainable params: 9,494,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d56153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411455b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24959 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1.0/255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "# validation_generator=test_datagen.flow_from_directory(\n",
    "#     validation_dir,\n",
    "#     batch_size=20,\n",
    "#     class_mode='binary',\n",
    "#     target_size=(150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d879e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  41/1248 [..............................] - ETA: 1:24 - loss: 1.3963 - accuracy: 0.5207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1248/1248 [==============================] - 85s 64ms/step - loss: 0.5995 - accuracy: 0.6918\n",
      "Epoch 2/10\n",
      "1248/1248 [==============================] - 80s 64ms/step - loss: 0.4573 - accuracy: 0.7874\n",
      "Epoch 3/10\n",
      "1248/1248 [==============================] - 72s 58ms/step - loss: 0.4027 - accuracy: 0.8200\n",
      "Epoch 4/10\n",
      "1248/1248 [==============================] - 105s 84ms/step - loss: 0.3696 - accuracy: 0.8417\n",
      "Epoch 5/10\n",
      "1248/1248 [==============================] - 112s 89ms/step - loss: 0.3408 - accuracy: 0.8571\n",
      "Epoch 6/10\n",
      "1248/1248 [==============================] - 68s 55ms/step - loss: 0.3253 - accuracy: 0.8666\n",
      "Epoch 7/10\n",
      "1248/1248 [==============================] - 76s 61ms/step - loss: 0.3137 - accuracy: 0.8752\n",
      "Epoch 8/10\n",
      "1248/1248 [==============================] - 78s 62ms/step - loss: 0.3052 - accuracy: 0.8793\n",
      "Epoch 9/10\n",
      "1248/1248 [==============================] - 77s 62ms/step - loss: 0.3046 - accuracy: 0.8830\n",
      "Epoch 10/10\n",
      "1248/1248 [==============================] - 77s 62ms/step - loss: 0.2992 - accuracy: 0.8868\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "  train_generator,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07922aa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'datasets/prediction/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_img, img_to_array\n\u001b[0;32m      4\u001b[0m image_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/prediction/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m image_files\u001b[38;5;241m=\u001b[39m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m images\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'datasets/prediction/'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "image_directory='datasets/prediction/'\n",
    "image_files=os.listdir(image_directory)\n",
    "images=[]\n",
    "for image_file in image_files:\n",
    "    image_path=os.path.join(image_directory,image_file)\n",
    "    image=load_img(image_path,target_size=(150,150))\n",
    "    image_array=img_to_array(image)\n",
    "    image_array/=255.0\n",
    "    x=np.expand_dims(image_array,axis=0)\n",
    "    images=np.vstack([x])\n",
    "    classes=model.predict(images,batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(image_file + 'is a dog')\n",
    "    else:\n",
    "        print(image_file + 'is a cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
